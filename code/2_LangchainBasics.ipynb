{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The basics of Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain-core langchain-community langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the OpenAI vanilla API to Langchain "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`prompt` is a `BasePromptTemplate`, which means it takes in a dictionary of template variables and produces a `PromptValue`. A `PromptValue` is a wrapper around a completed prompt that can be passed to either an LLM (which takes a string as input) or ChatModel (which takes a sequence of messages as input). It can work with either language model type because it defines logic both for producing BaseMessages and for producing a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a world class chef'), HumanMessage(content='Tell me the recipe for pasta alla norma')])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world class chef\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "prompt_value = prompt.invoke({\"input\": \"Tell me the recipe for pasta alla norma\"})\n",
    "prompt_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model\n",
    "\n",
    "The `PromptValue` is then passed to model. In this case our model is a `ChatModel`, meaning it will output a `BaseMessage`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Pasta alla Norma is a classic Sicilian pasta dish that features eggplant, tomatoes, basil, and ricotta salata cheese. Here's a simple recipe for you to try:\\n\\nIngredients:\\n- 1 medium eggplant, diced\\n- 2 cloves of garlic, minced\\n- 1 can of diced tomatoes\\n- 1/4 cup of olive oil\\n- Salt and pepper to taste\\n- 1/4 teaspoon red pepper flakes (optional)\\n- 1 pound of pasta (such as spaghetti or penne)\\n- Fresh basil leaves, torn\\n- Ricotta salata cheese, grated (or you can substitute with feta or Parmesan cheese)\\n\\nInstructions:\\n1. Start by salting the diced eggplant and letting it sit in a colander for about 30 minutes to draw out excess moisture and bitterness. Rinse and pat dry with paper towels.\\n\\n2. In a large skillet, heat the olive oil over medium heat. Add the eggplant and sauté until golden brown and softened, about 10-15 minutes.\\n\\n3. Add the minced garlic and red pepper flakes (if using) to the skillet and cook for another minute until fragrant.\\n\\n4. Pour in the diced tomatoes and season with salt and pepper. Let the sauce simmer for about 15-20 minutes until it thickens slightly.\\n\\n5. While the sauce is simmering, cook the pasta in a large pot of salted boiling water according to package instructions until al dente. Reserve some pasta water before draining.\\n\\n6. Once the pasta is cooked, add it to the skillet with the sauce and toss to combine. If the sauce is too thick, add some of the reserved pasta water to loosen it up.\\n\\n7. Serve the pasta alla Norma in bowls, topped with torn basil leaves and grated ricotta salata cheese.\\n\\nEnjoy your delicious Pasta alla Norma!\", response_metadata={'token_usage': {'completion_tokens': 381, 'prompt_tokens': 26, 'total_tokens': 407}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4d7bcd43-afb5-4051-b515-263737bc19ee-0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "model_response = model.invoke(prompt_value)\n",
    "model_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Chain\n",
    "\n",
    "A `chain` is a series of steps that process data through different steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Pasta alla Norma is a classic Sicilian dish that features pasta with eggplant, tomatoes, basil, and ricotta salata. Here's a simple recipe for Pasta alla Norma:\\n\\nIngredients:\\n- 1 medium eggplant, diced\\n- 2 cloves of garlic, minced\\n- 1 can (14 oz) of diced tomatoes\\n- 1/4 cup of olive oil\\n- Salt and pepper to taste\\n- Fresh basil leaves, chopped\\n- 12 oz of pasta (such as spaghetti or penne)\\n- Ricotta salata cheese, grated (or you can substitute with ricotta or parmesan cheese)\\n\\nInstructions:\\n1. Start by salting the diced eggplant and letting it sit for about 30 minutes to help remove excess moisture and bitterness. After 30 minutes, rinse the eggplant and pat it dry with paper towels.\\n2. Heat the olive oil in a large pan over medium heat. Add the eggplant and sauté until golden brown and tender, about 10-15 minutes.\\n3. Add the minced garlic to the pan and cook for another minute until fragrant.\\n4. Pour in the diced tomatoes and season with salt and pepper. Let the sauce simmer for about 10-15 minutes to allow the flavors to meld together.\\n5. In the meantime, cook the pasta in a large pot of salted boiling water according to package instructions. Reserve some pasta water before draining.\\n6. Once the pasta is cooked, add it to the pan with the eggplant and tomato sauce. Toss everything together, adding a splash of pasta water if needed to loosen the sauce.\\n7. Stir in the chopped basil leaves and adjust the seasoning with salt and pepper.\\n8. Serve the Pasta alla Norma hot, topped with grated ricotta salata cheese.\\n\\nEnjoy your delicious Pasta alla Norma!\", response_metadata={'token_usage': {'completion_tokens': 376, 'prompt_tokens': 26, 'total_tokens': 402}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7ea36759-4961-4657-ae5f-1d2a35f2211f-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world class chef\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\"input\": \"Tell me the recipe for pasta alla norma\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Output Parser\n",
    "\n",
    "Let's use the `StrOutputParser` object to display just the respone content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why was the cat sitting on the computer? Because it wanted to keep an eye on the mouse!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note how ChatPromptTemplate.from_template is another way to provide the model with instructions\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "chain.invoke({\"topic\": \"cats\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
